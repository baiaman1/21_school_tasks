# Авторизация и DI

## Contents

[[_TOC_]]

## Chapter I 

### Introduction

В этом блоке ты узнаешь, что такое сервис-ориентированная архитектура, микросервисная архитектура, авторизация и аутентификация, RBAC и CBAC, JWT, gRPC и DI.

## Chapter II

### Монолитная архитектура
Под монолитом понимают приложение как неделимую единицу. Традиционно монолитное решение — один исполняемый файл на стороне сервера и еще один — на стороне клиента.

Монолитная архитектура часто является хорошим вариантом для относительно небольшого или простого приложения с предсказуемой нагрузкой. Это, например, MVP (минимально жизнеспособный продукт) или веб-сайт, обслуживающий статический контент.

Традиционный подход к созданию приложений путем объединения всех функций в единую сущность, объединяющую интерфейс и серверную часть, по-прежнему актуален. Дело в том, что не всегда есть смысл в усложнении архитектуры. Если требования к сервису (например, к веб-сайту) включают только скорость, доступность и возможность обслуживания статического контента, который находится в свободном доступе, монолитная архитектура для таких целей — вполне естественный выбор. 


### SOA

SOA (**S**ervice-**O**riented **A**rchitecture) - метод разработки программного обеспечения, использующий программные компоненты (называемые сервисами) для создания бизнес-приложений. 

Каждый сервис предоставляет бизнес-возможности, причем сервисы могут взаимодействовать друг с другом будучи написанными на разных платформах и языках. Когда это используется? Для многократного использования сервисов в различных системах или для объединения независимых сервисов для выполнения сложных задач.

Например, многие приложения (даже внутри одной компании) требуют аутентификацию пользователя. Вместо того чтобы переписывать код аутентификации для всех бизнес-процессов, ты можешь создать единый сервис аутентификации и использовать его повторно для всех приложений.

Давай посмотрим на основные **преимущества** сервис-ориентированной архитектуры.

1) *Сокращение времени выхода на рынок*. В случае когда уже имеются готовые сервисы, которые можно переиспользовать, время разработки системы может серьезно сократиться.

2) *Эффективное обслуживание*. При развитой инфраструктуре обслуживать распределенную систему может быть проще в некоторых аспектах. Можно, например, обновлять сервисы по отдельности, не отключая всю систему целиком. А также сервисы можно хостить на разных машинах, что также даёт определенные преимущества

3) *Модульность*. Благодаря разбиению системы на сервисы, становится легко модифицировать её части.

<div align="center">

![soa](images/Backend_Project_4_0.jpg)

</div>

Итак, мы поняли, что SOA преследует замечательные идеи: упрощенное обслуживание, быстрый выход на рынок и т.д. Как это часто бывает, единого рецепта, как реализовать сервис-ориентированную архитектуру, нет. Однако есть набор принципов, следуя которым, вы сможете достичь поставленной цели.

1) *Обеспечение совместимости*. Каждый сервис включает документы описания, определяющие функциональность сервиса, и как она используется.

2) *Слабые зависимости*. Чем меньше зависимостей между сервисами, тем проще их модифицировать, так как изменения не будут затрагивать большое число внешних компонентов.

3) *Абстрагирование*. Для клиентов или пользователей сервис - это черный ящик. Они не обязаны знать, как он работает. Они лишь получают информацию о том, что он делает, через предоставленные контракты на обслуживание и другие документы с описанием сервиса.

Теперь посмотрим, из чего состоит сервис-ориентированная архитектура.

<div align="center">

![details](images/Backend_Project_4_1.jpg)

</div>

- Сервис - основной "строительный блок" SOA. Каждый сервис имеет интерфейс, реализацию и контракт.
    - Реализация - код сервиса.
    - Интерфейс (Контракт) - способы взаимодействия других сервисов или систем с данным сервисом.

- Поставщик сервиса создает, поддерживает и предоставляет один или несколько сервисов, которые могут использовать другие пользователи.

- Потребитель сервиса - тот, кто запрашивает у поставщика выполнение конкретного сервиса. Кстати, контракт как раз определяет правила, по которым поставщик и потребитель взаимодействуют друг с другом.

- Сервисный реестр - каталог доступных сервисов.

А как это все работает? Если сервисы более-менее независимы друг от друга, как они могут образовать целостную систему? Так вот, сервисы могут взаимодействовать с помощью установленных правил, определяющих передачу данных по сети. Эти правила также называют протоколами передачи данных. Например, сервисы могут взаимодействовать по RESTful API, SOAP, RPC-протоколы.

### Микросервисная архитектура
Микросервисная архитектура (MSA - **M**icro **S**ervice **A**rchitecture) - развитие SOA. Микросервисы очень похожи на сервисы, но как следует из названия, предоставляют более мелкий и атомарный бизнес-функционал. Микросервисы часто устраняют недостатки SOА в части масштабирования из-за возможного совместного использования ресурсов и делают ПО более совместимым с облачными корпоративными средами.

Для развертывания приложений на основе MSA часто используют контейнерные технологии, такие как Docker и Kubernetes.

В микросервисной архитектуре приложение разбивается на ряд независимо развертываемых сервисов, которые взаимодействуют с помощью API-интерфейсов. Благодаря такому подходу каждый отдельный сервис можно развертывать и масштабировать независимо от других. В результате команды могут быстрее и чаще поставлять объемные и сложные приложения. В отличие от монолитного приложения, с микросервисной архитектурой команды могут быстрее внедрять новые возможности и вносить изменения, при этом им не приходится переписывать большие фрагменты существующего кода.

Класс, но чем отличается MSA и SOA? Нельзя говорить, что MSA всегда строго лучше SOA. Правильнее сказать, что каждая из архитектур имеет свое назначение. Давай посмотрим на различия MSA и SOA в табличке.

| MSA                                                                            | SOA                                                                                                                                   |
|--------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------|
| Микросервисы используют, как правило, легковесные протоколы (REST/HTTP и т.д.) | SOA поддерживает мульти-протоколы.                                                                                                    |
| Концентрируется на разделении задач.                                           | Концентрируется на повторном использовании.                                                                                           |
| Используются простые системы обмена сообщениями.                               | Используется поставщик сервисов (так же называется Enterprise Service Bus (ESB) - сервисная шина) для коммуникации.                   |
| Микросервисы использую подход "разделять как можно меньше архитектуры".        | SOA использует подход "разделять как можно больше архитектуры" (устраняется повторное использование - один из основных принципов SOA) |
| Хорошо воспринимаются отказы (микросервисы практически независимы).            | Ошибки и отказы воспринимаются плохо в сравнении с MSA.                                                                               |
| Каждый микросервис использует собственную независимую базу данных.             | Сервисы в SOA разделяют единое хранилище данных.                                                                                      |
| Подходит для небольших веб-систем.                                             | Подходит для больших, сложных бизнес-приложений.                                                                                      |

Граница между SOA и MSA очень условна и размыта, поэтому многие вещи из таблицы могут быть верны для обоих архитектур.

Пример микросервисной архитектуры (Web API магазина) представлен на картинке снизу.

<div align="center">

![msa](images/Backend_Project_4_2.jpg)

</div>

### Плюсы микросервисной архитектуры
* Итеративная разработка. Архитектура программного обеспечения на основе микросервисов хорошо подходит для организации гибкой разработки ПО, основанной на итеративном подходе. Разбиение уже работающего приложения на отдельные, слабо связанные между собой сервисы означает, что новые возможности и функции могут быть проверены и добавлены без риска остановки приложения.
* Гибкость. Микросервисы обеспечивают большую гибкость процесса разработки ПО сразу на нескольких уровнях. Это позволяет разным командам одновременно работать над разными сервисами и упрощает интеграцию в процесс разработки новых членов команды, ведь разделенный на отдельные функциональные части код легче читать и понимать.
* Свобода в выборе технологического стека. В монолитной архитектуре, где сервисы тесно связаны, важно поддерживать согласованность технологий, используемых в приложении. Они также должны быть хорошо совместимы друг с другом, что характерно не для всех языков программирования и средств разработки ПО. Слабо связанные микросервисы обеспечивают гораздо большую свободу в выборе стека технологий. Вплоть до того, что команда разработчиков может даже создавать отдельные сервисы с очень разным набором инструментов разработки.
* Доступность. Одним из самых больших преимуществ архитектуры микросервисов является то, что слабо связанные сервисы обеспечивают большую надежность приложения и более высокую доступность. Если одна служба выходит из строя, то это, как правило, не влияет на остальную часть приложения, которое продолжит функционировать для пользователей.
* Масштабируемость. Еще одним плюсом микросервисов является то, что этот подход хорошо подходит для масштабирования приложений. Модульность микросервисов позволяет легко добавлять новые функции прямо в работающее приложение. Хотя первоначальные затраты на архитектуру микросервисов выше, ее масштабирование может быть значительно дешевле, чем у монолитного приложения, благодаря сочетанию уже упомянутых сильных сторон.
* Производительность. Также за счет разделения служб и нагрузки между несколькими серверами возможно значительно повысить производительность.

### Минусы микросервисной архитектуры
* Сложность синхронизации. Распределенная система, такая как микросервисы, неизбежно создает дополнительную сложность, поскольку ее части необходимо синхронизировать таким образом, чтобы они могли работать как единая программная система. И если службы разделены между серверами, вам придется подготовить инфраструктуру для взаимодействия микросервисов.
* Более высокие первоначальные затраты. Хотя попытки значительно масштабировать монолитное приложение могут оказаться сущим кошмаром, который приводит к резкому росту прямых затрат на разработку, архитектура микросервисов требует более высоких первоначальных затрат. Для каждого микросервиса требуется своя команда разработчиков (хотя одна команда может отвечать и за несколько). Кроме того, придется наладить и процесс автоматического тестирования и развертывания (CI/CD). Всё это приводит к более высоким первоначальным затратам.
* Потребность в DevOps. Распределенная система, такая как микросервисы, требует квалифицированной оркестровки, обычно с использованием Kubernetes и других инструментов и процессов DevOps. Это означает, что вам нанять хотя бы одного инженера DevOps, что также увеличит расходы.

### Аутентификация и авторизация

Страшные, очень похожие друг на друга слова. Что они означают? Дополнительно рассмотрим термин *идентификация*.

**Идентификация** — процедура, в результате выполнения которой для субъекта идентификации выявляется его идентификатор, однозначно определяющий этого субъекта в информационной системе. Если простыми словами, то это процесс определения, *кто* делает запрос к системе. 

**Аутентификация** — процедура проверки подлинности, например проверка подлинности пользователя путем сравнения введенного им пароля с паролем, сохраненным в базе данных. Проще говоря, это проверка, что тот, кто делает запрос, не выдает себя за кого-то другого.

**Авторизация** — предоставление определенному лицу или группе лиц прав на выполнение определенных действий. После успешной идентификации и авторизации пользователю надо дать права что-то делать в системе в соответствии с выбранной моделью доступа к ресурсам.

С этими процедурами ты встречаешься постоянно. Как пример можно рассмотреть доступ к Сбербанк Онлайн. Сначала ты вводишь логин (или номер телефона), по которому система определяет, в какую учетную запись ты пытаешься войти. Если идентификация успешна, переходим к процедуре аутентификации. Ты вводишь свой пароль. В случае успешного ввода пароля система может запросить ещё какой-то код (например, код из SMS) - это называется **двухфакторной аутентификацией**. В случае успеха, переходим к процедуре авторизации: система выдает права доступа к информации и твоих счетах, кредитах, бонусах и т.д.

### Модели доступа к ресурсам

Администрирование безопасности системы может быть очень дорогим и неэффективным, особенно если рассматривать каждого нового пользователя индивидуально и каждый раз принимать индивидуальное решение о его правах. Кроме того, в таком случае возможны ошибки, и, как следствие, утечки информации. Таким образом, очевидна необходимость в упорядоченном контроле прав пользователей с помощью проверенных моделей доступа.

В теории баз данных выделяют следующие модели доступа к данным:

- Мандатная (MAC - Mandatory Access Control)
- Избирательная (DAC - Discretionary Access Control)
- На основе ролей (RBAC - Role-Based Access Control)
- На основе атрибутов (ABAC - Attribute-Based Access Control)

Но, поскольку мы рассматриваем доступ именно к *системе*, выделяются только две модели - Role-Based Access Control и Claim-Based Access Control (RBAC и CBAC).

#### **RBAC**
Права пользователей группируются в группы, называемые **ролями**. И уже роли назначаются **субъектам**. Таким образом, исчезает сложность выделения прав: они уже логически сгруппированы в некоторую роль. Примеры ролей в случае с магазином: продавец, консультант (консультант, например, может не иметь доступа к методам сервиса продаж), покупатель, курьер и т.д.

Частой ошибкой при использовании RBAC является группировка пользователей в группы и выделение им прав вместо *группировки прав доступа* в роли, которые затем выделяются пользователям. 

Преимуществом RBAC можно назвать Segregation of Duties - разделение полномочий, которое часто соответствует реальному положению дел в бизнесе.

Недостатком RBAC является необходимость детальной разработки ролевой модели.

Пример на c# можно посмотреть в папке materials.


#### **CBAC**

"Claim" можно перевести по-разному, но сейчас будем использовать термин "утверждение". Что такое утверждение? Можно рассматривать его как некоторый тег/ярлык, повешенный на пользователя. Примеры: пенсионер, европеец, администратор и т.д. 

Данный подход явно шире, чем RBAC, поскольку модель, основанную на требованиях, легко свести к ролевой, оставив только одно утверждение с типом "роль" и присваивать ему значения "консультант", "администратор" и т.д. Смысл именно в том, что мы делаем более гибкую систему, добавляя несколько утверждений с разными типами.

В разных языках присутствуют разные средства для реализации рассмотренных моделей.

Пример на c# можно посмотреть в папке materials.

### JWT токены

Известно, что по методологии REST сервер не должен ничего знать о предыдущих состояниях какого-либо клиента. Клиент посылает запрос серверу сразу вместе со всей необходимой информацией.

Поскольку сервер не хранит данные о состоянии клиента, а в практически любой современной системе используется авторизация, необходим способ "сигнализировать" серверу о том, что клиент, посылающий запрос, уже прошёл авторизацию. Да, можно было бы каждый раз в параметрах запроса посылать логин и пароль, однако это крайне небезопасно. Решение - **JSON Web Token** (или **JWT**).

Идея токенов не такая сложная: давайте вместо логина и пароля в базе хранить токен и id пользователя, а токен выдавать при первом запросе с помощью некоторой хеш-функции от каких-то уникальных свойств пользователя (его id, логин, пароль). Таким образом, при последующих запросах не потребуется передача логина и пароля, достаточно передать токен. Часто токену устанавливают время жизни, по истечении которого он становится недействительным.

JWT имеет преимущества: он самодостаточен, всю необходимую информацию можно хранить в самом токене. Рассмотрим устройство токена.

#### Структура токена

Токен состоит из 3 основных частей:

- Заголовок (Header)
- Нагрузка (Payload)
- Подпись (Signature)

Заголовок и нагрузка формируются отдельно, затем на их основе вычисляется подпись.

Заголовок состоит из полей "тип" и "алгоритм" (хеширования подписи):
```
{
    "typ": "JWT",
    "alg": "HS256"
}
```
[Официальный сайт](jwt.io) предлагает только два варианта алгоритма хеширования: HS256 и RS256.

Нагрузка - любые данные, которые мы хотим держать внутри токена. Однако стандарт предусматривает несколько заранее определенных полей: iss (issuer), sub (subject), exp (expire time), iat (issued at) и т.д.

Пример payload:
```
{
    "iss": "Cool dev team",
    "sub": "auth",
    "my_attr_for_data": "I love ice cream!"
}
```

**Важно!** Нагрузка не шифруется, поэтому будьте осторожны.

Наконец, подпись вычисляется на основе заголовка и нагрузки. 

Сначала заголовок и нагрузка преобразуются из формата JSON в base64Url:

```
Header: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9
Payload: eyJpc3MiOiJDb29sIGRldiB0ZWFtIiwic3ViIjoiYXV0aCIsIm15X2F0dHJfZm9yX2RhdGEiOiJJIGxvdmUgaWNlIGNyZWFtISJ9
```

Затем, строки объединяются через точку и хешируются указанным алгоритмом. Пусть пароль пользователя - `qwerty123`. Тогда получим подпись следующей функцией:

```python
HS256('eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9' + '.' + 'eyJpc3MiOiJDb29sIGRldiB0ZWFtIiwic3ViIjoiYXV0aCIsIm15X2F0dHJfZm9yX2RhdGEiOiJJIGxvdmUgaWNlIGNyZWFtISJ9', 'qwerty123') = m-XiMqPrcoXQrORjJPjddx53DhB8lgAB-WGaA2iQGVs
```

Осталось получить сам токен, для этого надо соединить через точку header, payload и signature:
```
eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJDb29sIGRldiB0ZWFtIiwic3ViIjoiYXV0aCIsIm15X2F0dHJfZm9yX2RhdGEiOiJJIGxvdmUgaWNlIGNyZWFtISJ9.m-XiMqPrcoXQrORjJPjddx53DhB8lgAB-WGaA2iQGVs
```
Полученный токен можно протестировать [на официальном сайте](https://jwt.io/).

Не зная приватного ключа (пароля), нельзя изменить подпись. При некорректной подписи нельзя поменять данные (токен будет недействительным из-за неверной подписи). Таким образом, данные на сервере защищены от изменений.

Все вышеперечисленные действия можно проделать самостоятельно. Это отличное упражнение для того, чтобы убедиться, что JWT работает не как магия, а довольно простым и понятным способом.

После первого входа по паролю клиенту вернется сгенерированный JWT. При каждом следующем запросе клиент будет передавать API уже полученный JWT токен способом, который устанавливает API (как вариант, через заголовок или через параметр запроса). Сервер, при получении JWT, декодирует заголовок и нагрузку (проверяя зарезервированные поля). Затем составляется подпись (сервер знает секретный ключ / пароль пользователя), и, если она совпадает с подписью из токена, авторизация пройдена.

Конечно, можно и самостоятельно реализовать выше описанный алгоритм. Однако существует множество библиотек для авторизации с помощью JWT. Подробнее о них можно прочитать на официальном портале [JWT](https://jwt.io/libraries).

### gRPC

Методология REST приобрела невероятную популярность среди разработчиков. Однако в последние годы стала активно развиваться и другая технология - gRPC.

gRPC - современная высокопроизводительная платформа с открытым кодом, развивающая устаревший протокол удаленного вызова процедур RPC (Remote Procedure Call).

Цель RPC - сделать вызов удаленных процедур наиболее похожим на вызов локальной процедуры. Взаимодействие в RPC осуществляется по модели клиент-сервер. Клиент и сервер взаимодействуют не обычными HTTP запросами, а используют удаленный вызов процедур. Для указания формы контракта на вызываемые функции и типы данных используется язык IDL (Interface Description Language). Принцип работы RPC можно увидеть на картинке снизу.

<div align="center">

![rpc](images/Backend_Project_4_3.jpg)

</div>

gRPC копирует этот архитектурный стиль взаимодействия клиент-сервер с помощью вызовов функций. Получается, что gRPC - не новая концепция, а лишь развитие старых технологий.

Давай посмотрим, почему же gRPC приобрел такую популярность в последний годы.

1. Абстракция - это просто: используется вызов функции место HTTP запросов, которые могут сбивать с толку при чтении кода.

2. Поддерживается на многих языках.

3. Хорошая скорость выполнения запросов (эффективность).

Также gRPC применяется в микросервисной архитектуре, про которую ты только что прочитал. Как известно, микросервисы могут быть написаны на разных языках, и один из микросервисов может вызывать множество других микросервисов. Используя gRPC, мы абстрагируемся от технологий, используемых в нужных нам микросервисах. Всё сводится к классическому вызову процедуры в коде.

<div align="center">

![rpc-1](images/Backend_Project_4_4.jpg)

</div>

Типичное клиентское приложение gRPC вызывает локальную внутрипроцессную функцию, реализующую бизнес-операцию. Внутри эта локальная функция (по-сути, заглушка - stub) вызывает другую функцию на удаленном компьютере. То, что представляется локальным вызовом, по сути, становится прозрачным внепроцессным вызовом удаленной службы. "Под капотом" RPC реализует сетевой обмен данными типа "point to point", сериализацию и выполнение кода на разных компьютерах.

Таким образом, код приложения ориентирован на бизнес-функции, в то время как gRPC обрабатывает коммуникации.

Нельзя ещё раз не отметить производительность gRPC. Если gRPC, по-сути, использует те же самые идеи, что были предложены в классическом RPC, что тогда делает его особенным? Ответ: HTTP / 2, а также односторонние и двусторонние стримы, что позволяют использовать gRPC для потоковой и событийной передачи данных в обе стороны.

В 2015 году Google запустил поддержку протокола HTTP / 2 на замену старому HTTP / 1.1 в браузере Chrome. В традиционном протоколе HTTP невозможно отправить несколько запросов или получить несколько ответов вместе в одном соединении. Для каждого из них необходимо будет создать новое соединение. Этот вид мультиплексирования запроса / ответа стал возможным в HTTP / 2. Он позволяет получать полезные данные из нескольких запросов с одним и тем же заголовком, таким образом идентифицируя его как один запрос. 

Кроме того, была решена проблема огромных заголовков в запросах. HTTP / 2 имеет очень интересную стратегию под названием HPack, чтобы справиться с этим. Во-первых, все в HTTP / 2 кодируется перед отправкой, включая заголовки. Это действительно помогает с производительностью, но это не самое главное в сжатии заголовков. HTTP / 2 отображает заголовок как на стороне клиента, так и на стороне сервера. Исходя из этого, HTTP / 2 может узнать, содержит ли заголовок то же значение, и отправляет значение заголовка, только если оно отличается от предыдущего заголовка.

gRPC - это бинарный протокол, использующий для сериализации своих фреймов протокол от Google - protobuf.

#### Protobuf

Осталось поговорить про Protobuf (от Protocol Buffer) - наиболее часто используемый язык определения интерфейса (IDL). Здесь хранятся основные данные и функциональные контракты в виде прото-файла.

Описываются контракты в файлах с расширением `.proto`. Основываясь на прото-файле, компилятор `protoc` генерирует код как клиента, так и сервера. Код включает в себя:

- Типизированные объекты, разделяемые клиентом и сервером.

- Типизированный базовый класс, реализующий всё взаимодействие по сети, который можно позже унаследовать и расширить.

- Заглушка клиента (client stub), которая вызывает необходимые службы gRPC для вызова удаленной процедуры.

Во время выполнения, каждое сообщение сериализуется в стандартное представление Protobuf и посылается от клиента к серверу (или наоборот). В отличие от JSON или XML, Protobuf сообщения сериализуются в бинарную последовательность байтов.

Пример, как выглядит proto-файл для [Hello, world!](https://github.com/grpc/grpc-go/tree/master/examples/helloworld) с использованием gRPC на Go представлен ниже.

```proto
// Copyright 2015 gRPC authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

syntax = "proto3";

option go_package = "google.golang.org/grpc/examples/helloworld/helloworld";
option java_multiple_files = true;
option java_package = "io.grpc.examples.helloworld";
option java_outer_classname = "HelloWorldProto";

package helloworld;

// The greeting service definition.
service Greeter {
  // Sends a greeting
  rpc SayHello (HelloRequest) returns (HelloReply) {}
}

// The request message containing the user's name.
message HelloRequest {
  string name = 1;
}

// The response message containing the greetings
message HelloReply {
  string message = 1;
}
```

gRPC предлагает комплексную поддержку в большинстве популярных стеков разработки, включая Java, JavaScript, C#, Go, Swift и NodeJS.

Таким образом, gRPC - интересная замена REST API, которую можно использовать в своих проектах. Ты можешь дополнительно рассмотреть, что такое метаданные, как работает потоковая передача, перехватчики и про балансировку нагрузки в gRPC. Это довольно интересная тема, а главное - бурно развивающаяся. 

### Dependency Injection, IoC-контейнеры

Напоследок поговорим про очень интересный паттерн, который используется при проектировании программных компонентов - внедрение зависимостей (Dependency Injection, DI).

В соответствии с принципом единой ответственности (SRP), объект отдает заботу о построении требуемых ему зависимостей внешнему общему механизму (Dependency Injector). Вводится понятие DI-контейнера или IoC-контейнера, который сохраняет конкретные реализации заданного интерфейса или базового класса и позже "прокидывает" их в конструкторы классов.

<div align="center">

![di](images/Backend_Project_4_5.jpg)

</div>

Таким образом, в коде не вызывается явно конструктор класса. Класс, в который зависимость прокидывается, не знает ничего о прокидываемой реализации, он пользуется лишь интерфейсом. Это позволяет с легкостью подменять реализацию интерфейсов в программе.

<div align="center">

![di-1](images/Backend_Project_4_6.jpg)

</div>

 Этот паттерн реализован в .NET из коробки в ASP.NET и в других языках или фреймворках:
* Java Spring: основными пакетами Spring Framework IoC контейнера являются org.springframework.beans и org.springframework.context;
* GO: [Wire](https://github.com/google/wire) от Google и [Fx](https://github.com/uber-go/fx) от Uber (там внутри используется [dig](https://github.com/uber-go/dig));
* Python: [opyoid](https://github.com/illuin-tech/opyoid) 

Пример на c# можно посмотреть в папке materials.

## Chapter III

1. Если в блоке 2 не был использован паттерн Dependency injection, то в этом блоке он обязательно должен быть. Реализуйте прокидывание реализаций, используя интерфейсы через IOC-контейнер.
2.  Необходимо реализовать сервис авторизации (отдельное приложение), используя который можно будет аутентифицировать и авторизовать пользователей для магазина бытовой техники.
   2.1. Сервис авторизации должен иметь своё хранилище (PostgreSQL). Для этого создаёте новую базу данных и прокидываете строку подключения внутрь своего сервиса (Не новая таблица, а новая база!).
   2.2. Сервис авторизации должен предоставлять взаимодействие только лишь посредством протокола gRPC. Настройте его в качестве gRPC сервера, опишите .proto файл, с описанием предоставляемых методов.
   2.3. Сервис авторизации должен предоставлять следующие методы:
    2.3.1. Создание пользователя по входным данным (почта, имя, фамилия, номер телефона, пароль), возвращает подписанный токен.
    2.3.2. Необходимо соблюсти один из важнейших принципов компьютерной безопасности: система не должна хранить пароли своих пользователей в открытом виде. Пароли в базе необходимо хранить в захэшированном виде с солью (произвольной сконкатенированной до хэширования строкой). Также нельзя брать устаревшие и имеющие уязвимости алгоритмы хэширования md5 и sha1. Таким образом, даже если ваша база данных попадет в руки злоумышленников, они не узнают реальные пароли, которыми пользуются ваши клиенты.
    2.3.3. Проверка пары логин-пароль (аутентифицировать пользователя), возвращает токен.
    2.3.4. Изменение пароля пользователя
    2.3.5. Метод восстановления пароля: Отправки пароля на почту пользователя (Саму отправку на почту реализовывать не нужно. Вместо этого, реализовать заглушку отправки на почту в виде вывода пароля в консоль сервиса авторизации)
3. Добавить метод регистрации (/register), авторизации(/auth), восстановления пароля(/reset) для магазина бытовой техники. Данные методы не подвергаются аутентификации, а всего лишь ходят в сервис авторизации для проверки или создания данных.
4. Реализовать авторизацию ручек всех API на основе верификации в сервисе аутентификации. Для аутентификации пользователя необходимо ходить в сервис авторизации и подтверждать валидность токена. Если токен валиден, то метод доступен, если нет - возвращать 401.
   4.1. Авторизацию в методах контроллера необходимо сделать на основе самописного атрибута авторизации, логика обработки которого лежит в middleware приложения. Т.е. прежде чем пустить запрос в обработчик, необходимо аутенцифицировать пользователя.
   4.2. JWT токен необходимо передавать в Authorization header.

Т.е. аутентификатор (middleware) ходит в написанный тобой сервис авторизации по gRPC и в случае успеха пускает в обработчик. 

**Важно!** Не забудь, что gRPC работает поверх http/2

💡 [Нажми тут](https://forms.yandex.ru/cloud/6470652cc769f11591b7a285/), **чтобы поделиться с нами обратной связью на этот проект**. Это анонимно и поможет команде Педаго сделать твоё обучение лучше.
